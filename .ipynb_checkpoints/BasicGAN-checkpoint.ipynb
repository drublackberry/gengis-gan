{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Generating the real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQAQESkpBYCISEkpAERESur/A2n3qMxHkj/UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_y(x):\n",
    "    return 10 + x**2\n",
    "\n",
    "def sample_data(n=10000, scale=100):\n",
    "    x = scale*(np.random.random_sample((n, ))-0.5)\n",
    "    y = get_y(x)\n",
    "    return np.array(list(zip(x,y)))\n",
    "\n",
    "def sample_Z(m, n):\n",
    "    return np.random.random_sample((m, n))\n",
    "\n",
    "data = sample_data()\n",
    "plt.plot(data.transpose()[0], data.transpose()[1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GAN definition\n",
    "\n",
    "* $ G(Z) $ is the function that generates synthetic (fake) samples\n",
    "* $ D(X) $ is the function that discriminates X for either being real or fake, outputs probability of real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(Z, hsize=[16, 16], reuse=False):\n",
    "    with tf.variable_scope(\"GAN/Generator\", reuse=reuse):\n",
    "        h1 = tf.layers.dense(Z, hsize[0], activation=tf.nn.leaky_relu)\n",
    "        h2 = tf.layers.dense(h1, hsize[1], activation=tf.nn.leaky_relu)\n",
    "        out = tf.layers.dense(h2, 2)  # generate pairs (x,y) of synthetic data\n",
    "    return out\n",
    "\n",
    "def discriminator(X, hsize=[16, 16], reuse=False):\n",
    "    with tf.variable_scope(\"GAN/Discriminator\", reuse=reuse):\n",
    "        h1 = tf.layers.dense(X, hsize[0], activation=tf.nn.leaky_relu)\n",
    "        h2 = tf.layers.dense(h1, hsize[1], activation=tf.nn.leaky_relu)\n",
    "        h3 = tf.layers.dense(h2, 2)  # logit, in 2D hyperspace, before logarithm\n",
    "        out = tf.layers.dense(h3, 1)  # probability of real (P(x|x is real) = 1)\n",
    "    return out, h3  # outputs of activation of last hidden layer to understand discriminator evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Building the GAN's graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value GAN/Generator/dense/kernel\n\t [[Node: GAN/Generator/dense/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GAN/Generator/dense/kernel)]]\n\nCaused by op 'GAN/Generator/dense/kernel/read', defined at:\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-920e67dda5d8>\", line 6, in <module>\n    G_sample = generator(Z)  # fake samples\n  File \"<ipython-input-3-bfe839682880>\", line 3, in generator\n    h1 = tf.layers.dense(Z, hsize[0], activation=tf.nn.leaky_relu)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 253, in dense\n    return layer.apply(inputs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 138, in build\n    trainable=True)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/training/checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 397, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3187, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value GAN/Generator/dense/kernel\n\t [[Node: GAN/Generator/dense/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GAN/Generator/dense/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value GAN/Generator/dense/kernel\n\t [[Node: GAN/Generator/dense/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GAN/Generator/dense/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-920e67dda5d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mZ_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdisc_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mZ_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run {}, Generator loss = {}, Discriminator loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value GAN/Generator/dense/kernel\n\t [[Node: GAN/Generator/dense/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GAN/Generator/dense/kernel)]]\n\nCaused by op 'GAN/Generator/dense/kernel/read', defined at:\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-920e67dda5d8>\", line 6, in <module>\n    G_sample = generator(Z)  # fake samples\n  File \"<ipython-input-3-bfe839682880>\", line 3, in generator\n    h1 = tf.layers.dense(Z, hsize[0], activation=tf.nn.leaky_relu)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 253, in dense\n    return layer.apply(inputs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 138, in build\n    trainable=True)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/training/checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 397, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3187, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/andreu/miniconda3/envs/image-recognition/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value GAN/Generator/dense/kernel\n\t [[Node: GAN/Generator/dense/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GAN/Generator/dense/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "# variable placeholders\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Z = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# graph\n",
    "G_sample = generator(Z)  # fake samples\n",
    "r_logits, r_rep = discriminator(X)  # real samples discrimination\n",
    "f_logits, f_rep = discriminator(G_sample, reuse=True)  # fake samples discrimination, it's the same discriminator so reuse\n",
    "\n",
    "# loss functions\n",
    "# discriminator loss is log(D(x)) + log(1-D(G(z)))\n",
    "disc_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=r_logits, labels=tf.ones_like(r_logits)) +\n",
    "                           tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits, labels=tf.zeros_like(f_logits)))\n",
    "# generator loss is log(G(z))\n",
    "gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits, labels=tf.ones_like(f_logits)))\n",
    "\n",
    "# optimizers\n",
    "# we collect the variables to be updated using scope and var_list\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"GAN/Generator\")\n",
    "gen_step = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(gen_loss, var_list=gen_vars)  # G train step\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"GAN/Discriminator\")\n",
    "disc_step = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(disc_loss, var_list=disc_vars)  # D train step\n",
    "\n",
    "# train\n",
    "batch_size = 1000\n",
    "n_iter = 10000\n",
    "with tf.Session() as sess:\n",
    "    for i in range(n_iter):\n",
    "        X_batch = sample_data(n=batch_size)\n",
    "        Z_batch = sample_Z(batch_size, 2)\n",
    "        _, dloss = sess.run([disc_step, disc_loss], feed_dict={X:X_batch, Z:Z_batch})\n",
    "        _, gloss = sess.run([gen_step,gen_loss], feed_dict={Z: Z_batch})\n",
    "        print(\"Run {}, Generator loss = {}, Discriminator loss = {}\".format(gloss, dloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
