{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import yaml\n",
    "from abc import abstractmethod\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module confEstimator\n",
    "class TensorDict(dict):\n",
    "    \"\"\"\n",
    "    Class that contains a dictionary of tensors\n",
    "    \"\"\"\n",
    "    def last(self):\n",
    "        return self.get(list(self.keys())[-1])\n",
    "    \n",
    "    def get_many(self, t_list):\n",
    "        return {x: self.get(x) for x in t_list}\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"** Specified Tensor Architecture **\")\n",
    "        for k, v in self.items():\n",
    "            print(\"{}: {}\".format(k, v))       \n",
    "        print(\"**\")\n",
    "            \n",
    "activation_dict = {\"relu\": tf.nn.relu, None: None, \"None\": None}\n",
    "\n",
    "def create_conv_layer(tensor_in, spec, name, mode=tf.estimator.ModeKeys.TRAIN):\n",
    "    return {name: tf.layers.conv2d(inputs=tensor_in, \n",
    "                                   filters=spec['filters'],\n",
    "                                   kernel_size=spec['kernel_size'],\n",
    "                                   padding=spec['padding'],\n",
    "                                   activation=activation_dict[spec['activation']],\n",
    "                                   name=name)}\n",
    "\n",
    "def create_maxpool_layer(tensor_in, spec, name, mode=tf.estimator.ModeKeys.TRAIN):\n",
    "    return {name: tf.layers.max_pooling2d(inputs=tensor_in,\n",
    "                                          pool_size=spec['pool_size'],\n",
    "                                          strides=spec['strides'],\n",
    "                                          name=name)}\n",
    "\n",
    "def create_dense_layer(tensor_in, spec, name, mode=tf.estimator.ModeKeys.TRAIN):\n",
    "    # creates an extra layer that must be flattened as well\n",
    "    out = {}\n",
    "    out[name+'_flatten'] = tf.reshape(tensor_in, [-1, np.prod(tensor_in.shape[1:4])])\n",
    "    out[name] = tf.layers.dense(inputs=out[name+'_flatten'],\n",
    "                                units=spec['units'],\n",
    "                                activation=activation_dict[spec['activation']],\n",
    "                                name=name)\n",
    "    return out\n",
    "                      \n",
    "def create_dropout_layer(tensor_in, spec, name, mode=tf.estimator.ModeKeys.TRAIN):\n",
    "    return {name: tf.layers.dropout(inputs=tensor_in, rate=spec['rate'], training = mode == tf.estimator.ModeKeys.TRAIN) }\n",
    "\n",
    "l_dict = {'CONV':create_conv_layer, 'POOL':create_maxpool_layer, 'FC': create_dense_layer, 'DROP': create_dropout_layer}\n",
    "\n",
    "def tensorboard_summaries(conv_layers=None, dense_layers=None):\n",
    "    if conv_layers is not None:\n",
    "        for cl_name, cl in conv_layers.items():\n",
    "            shape = cl.shape.as_list()\n",
    "            for f in range(shape[3]):\n",
    "                tf.summary.image(\"{}/filter/{}\".format(cl_name, f), tf.reshape(cl[:, :, :, f], [tf.shape(cl)[0], shape[1], shape[2], 1]))  \n",
    "    if dense_layers is not None:\n",
    "        for dl_name, dl in dense_layers.items():\n",
    "           tf.summary.histogram(\"{}/weights\".format(dl_name), dl) \n",
    "\n",
    "        \n",
    "class confEstimator(tf.estimator.Estimator):\n",
    "    \"\"\"\n",
    "    Class that allows building a certain neural-net based on a configuration YAML file. It must be overcharged.\n",
    "    \"\"\"\n",
    "            \n",
    "    def __init__(self, conf_file, **kwargs):\n",
    "        self.conf_file = conf_file\n",
    "        with open(conf_file) as f:\n",
    "            self.conf = yaml.load(f)\n",
    "        super(confEstimator, self).__init__(self.conf_model_fn, **kwargs)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def conf_model_fn(self, features, labels, model):\n",
    "        pass\n",
    "    \n",
    "    def _get_tensor_dict(self, data_in, mode):\n",
    "        tensor_dict = TensorDict()  # will contain all the information on the layers and tensors\n",
    "        # if data_in is a dictionary (e.g. 'x'), unroll\n",
    "        if type(data_in)==dict:  # conver to np.array\n",
    "            shaped_data_in = np.array([data_in[k] for k in data_in.keys()])\n",
    "            if len(data_in.keys())==1:  # remove unncessary dimension\n",
    "                shaped_data_in = shaped_data_in[0]\n",
    "        else:\n",
    "            shaped_data_in = data_in\n",
    "        num_channels = 1 if len(shaped_data_in.shape)==3 else shaped_data_in.shape[3]\n",
    "        tensor_dict['input_layer'] = tf.reshape(shaped_data_in, [-1, shaped_data_in.shape[1], shaped_data_in.shape[2], num_channels]) \n",
    "        for l_name, l_def in self.conf['layers'].items():\n",
    "            tensor_dict.update(l_dict[l_def['type']](tensor_dict.last(), l_def['specs'], l_name, mode))\n",
    "        return tensor_dict\n",
    "    \n",
    "    def get_layers_of_type(self, l_type):\n",
    "        return [l_name for l_name, l_def in self.conf['layers'].items() if l_def['type']==l_type]\n",
    "    \n",
    "\n",
    "class confRegressorEstimator(confEstimator):\n",
    "    \"\"\"\n",
    "    Class that allows for a image classification based on a convolutional neural-net which architecture is on a YAML file\n",
    "    \"\"\"\n",
    "    def conf_model_fn(self, features, labels, mode):\n",
    "\n",
    "        # tensor_dict\n",
    "        td =  self._get_tensor_dict(features, mode)\n",
    "        #td.summary()\n",
    "        \n",
    "        # tensorboard summary for weights and variables in the layers   \n",
    "        tensorboard_summaries(conv_layers=td.get_many(self.get_layers_of_type('CONV')), \n",
    "                             dense_layers=td.get_many(self.get_layers_of_type('FC')))\n",
    "\n",
    "        # predictions\n",
    "        predictions = {\n",
    "            \"predictions\": td.last()  # return the last predicted image\n",
    "        }\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            # wrap predictions into a class and return EstimatorSpec object\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "        # minimization function\n",
    "        loss = tf.losses.mean_squared_error(labels=labels, predictions=td.last())  # loss is a scalar tensor\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.conf['learning_rate'])\n",
    "            train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"predictions\"]),\n",
    "            \"mean_absolute_error\": tf.metrics.mean_absolute_error(labels=labels, predictions=predictions[\"predictions\"]), \n",
    "            \"RMS\": tf.metrics.root_mean_squared_error(labels=labels, predictions=predictions[\"predictions\"])\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"/jup/projects/mtgtools2/\")  # ensure we find the MTG libraries\n",
    "import pymtg.fci.esl.training_data as esl\n",
    "import pymtg\n",
    "\n",
    "RETINAS_JSON = Path(pymtg.__file__).parent.parent / \"test/FCI_ESL/pyesl/config/retinas.json\"\n",
    "ESL_PATH = Path(\"/mnt/data/FCI/ESL/nc/output/20170615T152646/ch123/\")\n",
    "FCI_PATH = Path(\"/mnt/data/FCI/ESL/nc/swaths/\")\n",
    "\n",
    "def collapse_scene(scene, step=1):\n",
    "    col_scene = scene[0]\n",
    "    for s in scene[1:]:\n",
    "        col_scene = np.insert(col_scene, -step, s.transpose()[-step], axis=1)  # create single input scene.\n",
    "    return col_scene\n",
    "\n",
    "def plot_scene(scene):\n",
    "    plt.imshow(collapse_scene(scene))\n",
    "    plt.title('Input scene')\n",
    "    plt.show()\n",
    "\n",
    "def plot_esl(esl):\n",
    "    plt.imshow(esl)\n",
    "    plt.title('ESL')\n",
    "    plt.show()\n",
    "    \n",
    "def get_model_name(name='Unnamed_conf_model'):\n",
    "    d = datetime.datetime.now()\n",
    "    return \"{}_{}\".format(name, d.strftime(\"%Y%m%dT%H%M%S\"))\n",
    "                          \n",
    "def get_model_dir(model_dir, **kwargs):\n",
    "    return \"{}{}\".format(model_dir, get_model_name(**kwargs))\n",
    "                          \n",
    "    \n",
    "def input_fn(size, train_or_test='train', collapsed=False, num_batches=1, mode=tf.estimator.ModeKeys.TRAIN, plot_data=False):\n",
    "    files = esl.prepare_training_data(FCI_PATH, ESL_PATH, 0, str(RETINAS_JSON))\n",
    "    out_batch = list(files[train_or_test].batches(\"ch123\", size, 20000, num_batches=num_batches))  # use always 'train', 'test' is not validated\n",
    "    if collapsed:\n",
    "        features = np.array([collapse_scene(out_batch[i][0]) for i in range(num_batches)])\n",
    "        labels = np.array([out_batch[i][1].flatten() for i in range(num_batches)])\n",
    "    else:\n",
    "        features = out_batch[0][0]  # only one batch\n",
    "        labels = out_batch[0][1]    \n",
    "    if plot_data:  # for validation purposes during prediction, will plot only the first image\n",
    "        if collapsed:\n",
    "            for f in features:\n",
    "                plt.imshow(f)\n",
    "                plt.show()\n",
    "        else:\n",
    "            plot_scene(features)\n",
    "            plot_esl(out_batch[0][1])    \n",
    "    dataset = tf.data.Dataset.from_tensors(({'features': features}, labels))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/mnt/data/tensorboardesl_cnn_collapsed_20180607T133932', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f185d4dc278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /mnt/data/tensorboardesl_cnn_collapsed_20180607T133932/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0056266, step = 1\n",
      "INFO:tensorflow:Loss for final step: 0.0056266.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-07-13:46:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/data/tensorboardesl_cnn_collapsed_20180607T133932/model.ckpt-1\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "SIZE = 100\n",
    "TRAIN_STEPS = 10\n",
    "TEST_STEPS=10\n",
    "MODEL = 'esl_cnn_collapsed'\n",
    "NUM_BATCHES = 10\n",
    "COLLAPSED = True\n",
    "\n",
    "# config\n",
    "run_config = tf.estimator.RunConfig(model_dir=get_model_dir(\"/mnt/data/tensorboard\", name=MODEL),\n",
    "                                    save_summary_steps=10, \n",
    "                                    save_checkpoints_steps=10)\n",
    "                        \n",
    "# create the estimator\n",
    "esl_regressor = confRegressorEstimator('example_config.yml', config=run_config)\n",
    "                                       \n",
    "train_spec = tf.estimator.TrainSpec(input_fn=partial(input_fn, size=SIZE, num_batches=NUM_BATCHES, collapsed=COLLAPSED), \n",
    "                                    max_steps=TRAIN_STEPS)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=partial(input_fn, size=SIZE, num_batches=NUM_BATCHES, collapsed=COLLAPSED),\n",
    "                                  steps=TEST_STEPS)\n",
    "\n",
    "tf.estimator.train_and_evaluate(esl_regressor, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single evaluation\n",
    "foo = esl_regressor.evaluate(input_fn=partial(input_fn, size=TEST_SIZE), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = esl_regressor.predict(input_fn=partial(eval_input_fn, size=100, plot_data=True))\n",
    "pred_esl = np.array([p['predictions'] for p in foo])\n",
    "\n",
    "plt.imshow(pred_esl)\n",
    "plt.title('Retrieved ESL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
